{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TH NÃ¼rnberg - Neural Network Translator - Christoph Brandl, Philipp Grandeit\n",
    "\n",
    "# Build sample neural networks for the neural network translator\n",
    "\n",
    "This jupyter notebooks provides everything you need to build sample neural networks with tensorflow (keras) which you can later translate with the neural network translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('out'):\n",
    "    os.makedirs('out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Pooling 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a neural network only consisting of one single average pooling 1D layer. The created model can then be used to validate the implementation of the average pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step we will prepare all the necessary data to build and train this simple neural network. Since the pooling layer is a linear process no learning will take place in this step. Hence, it does not matter which data we will use. The only thing we have to make sure is that the shape of the input and output data is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([[1,2,3,4,5,6]])\n",
    "data_y = np.array([[1,2,3]])\n",
    "\n",
    "data_x = scale(data_x,axis=0)\n",
    "data_x = tf.reshape(data_x,[-1,6,1])\n",
    "data_y = tf.reshape(data_y,[-1,3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will actually build the model. You can change the different parameters of the layer to play around with different settings and fully test the average pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.AveragePooling1D(pool_size=2, strides=2 ,padding='valid', input_shape = (6,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will throw a warning since we do not actually learn anything. Since this is the planned behaviour, the warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_x, data_y, epochs=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our model to a .h5 file to translate it with the neural network translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/avg_pool_1d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will prepare a sample input to check if the result of our build model is equal to the result of our translated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array([[1.0,2,3,4,5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more convenient, we will prepare the input data so that we can simply copy and paste the values in the serial dialog of our arduino ide. We can now simply copy and paste the values inbetween of the square brackets [ ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_array.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will perform the prediction with the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.reshape(input_array,[1,6,1])\n",
    "\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the output of our trained model with the output of the neural network translator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Pooling 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we repeat the building process but instead of a 1D average pooling layer we will build a neural network only consisting of one single average pooling 2D layer. The created model can then be again used to validate the implementation of the average pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step we will prepare all the necessary data to build and train this simple neural network. Since the pooling layer is a linear process no learning will take place in this step. Hence, it does not matter which data we will use. The only thing we have to make sure is that the shape of the input and output data is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([[1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1]])\n",
    "data_y = np.array([[[1],[1]],[[1],[1]],[[1],[1]],[[1],[1]]])\n",
    "\n",
    "data_x = scale(data_x,axis=0)\n",
    "data_x = tf.reshape(data_x,[-1,5,3,1])\n",
    "data_y = tf.reshape(data_y,[-1,4,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will actually build the model. You can change the different parameters of the layer to play around with different settings and fully test the average pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=(1,1),padding='valid', input_shape = (5,3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will throw a warning since we do not actually learn anything. Since this is the planned behaviour, the warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_x, data_y, epochs=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our model to a .h5 file to translate it with the neural network translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/avg_pool_2d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will prepare a sample input to check if the result of our build model is equal to the result of our translated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array([[26,1,37], [115,189,31.3], [31.3,29.6,103], [0.205,0,83], [41,36,2.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more convenient, we will prepare the input data so that we can simply copy and paste the values in the serial dialog of our arduino ide. We can now simply copy and paste the values inbetween of the square brackets [ ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_array.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will perform the prediction with the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.reshape(input_array,[1,5,3,1])\n",
    "\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the output of our trained model with the output of the neural network translator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a neural network only consisting of one single max pooling 1D layer. The created model can then be used to validate the implementation of the average pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step we will prepare all the necessary data to build and train this simple neural network. Since the pooling layer is a linear process no learning will take place in this step. Hence, it does not matter which data we will use. The only thing we have to make sure is that the shape of the input and output data is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([[1,2,3,4,5,6]])\n",
    "data_y = np.array([[1,2,3]])\n",
    "\n",
    "data_x = scale(data_x,axis=0)\n",
    "data_x = tf.reshape(data_x,[-1,6,1])\n",
    "data_y = tf.reshape(data_y,[-1,3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will actually build the model. You can change the different parameters of the layer to play around with different settings and fully test the average pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2, strides=2 ,padding='valid', input_shape = (6,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will throw a warning since we do not actually learn anything. Since this is the planned behaviour, the warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_x, data_y, epochs=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our model to a .h5 file to translate it with the neural network translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/max_pool_1d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will prepare a sample input to check if the result of our build model is equal to the result of our translated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array([[1.0,2,3,4,5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more convenient, we will prepare the input data so that we can simply copy and paste the values in the serial dialog of our arduino ide. We can now simply copy and paste the values inbetween of the square brackets [ ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_array.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will perform the prediction with the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.reshape(input_array,[1,6,1])\n",
    "\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the output of our trained model with the output of the neural network translator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we repeat the building process but instead of a 1D average pooling layer we will build a neural network only consisting of one single average pooling 2D layer. The created model can then be again used to validate the implementation of the average pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step we will prepare all the necessary data to build and train this simple neural network. Since the pooling layer is a linear process no learning will take place in this step. Hence, it does not matter which data we will use. The only thing we have to make sure is that the shape of the input and output data is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([[1,1,1], [1,1,1], [1,1,1], [1,1,1], [1,1,1]])\n",
    "data_y = np.array([[[1],[1]],[[1],[1]],[[1],[1]],[[1],[1]]])\n",
    "\n",
    "data_x = scale(data_x,axis=0)\n",
    "data_x = tf.reshape(data_x,[-1,5,3,1])\n",
    "data_y = tf.reshape(data_y,[-1,4,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will actually build the model. You can change the different parameters of the layer to play around with different settings and fully test the average pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1),padding='valid', input_shape = (5,3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will throw a warning since we do not actually learn anything. Since this is the planned behaviour, the warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_x, data_y, epochs=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save our model to a .h5 file to translate it with the neural network translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/max_pool_2d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will prepare a sample input to check if the result of our build model is equal to the result of our translated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array([[26,1,37], [115,189,31.3], [31.3,29.6,103], [0.205,0,83], [41,36,2.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more convenient, we will prepare the input data so that we can simply copy and paste the values in the serial dialog of our arduino ide. We can now simply copy and paste the values inbetween of the square brackets [ ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_array.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will perform the prediction with the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.reshape(input_array,[1,5,3,1])\n",
    "\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the output of our trained model with the output of the neural network translator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layer Diabates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"diabetes.csv\", delimiter=\",\", skiprows=1 )\n",
    "diabetes_X = dataset[:,0:8]\n",
    "diabetes_Y = dataset[:,8]\n",
    "diabetes_X = scale(diabetes_X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(8, input_dim=8, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(diabetes_X, diabetes_Y, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/2_layer_diabetes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = dataset[0][0:8]\n",
    "input = tf.reshape(input_array,[1,8])\n",
    "print(np.array(input[0]).flatten().tolist())\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Layer diabates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"diabetes.csv\", delimiter=\",\", skiprows=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (final net: extra layer, first layer enlarged, relu activation func.)\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, input_dim=8, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(diabetes_X, diabetes_Y, epochs=300, batch_size=10)\n",
    "model.save('out/3_layer_diabetes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = dataset[0][0:8]\n",
    "input = tf.reshape(input_array,[1,8])\n",
    "print(np.array(input[0]).flatten().tolist())\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_images = tf.reshape(train_images, [-1, 28, 28, 1])\n",
    "test_images = tf.reshape(test_images, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.AveragePooling2D(input_shape=(28, 28, 1), pool_size=(4,4),strides=(4,4), padding='valid', data_format='channels_last'),\n",
    "    #keras.layers.AveragePooling2D(pool_size=(2,2),strides=(2,2), padding='valid', data_format='channels_last'),\n",
    "    #keras.layers.AveragePooling2D(pool_size=(2,2),strides=(2,2), padding='valid', data_format='channels_last'),\n",
    "    keras.layers.Flatten(),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('out/fashion_mnist_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_images[0]).flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = test_images[0][0:784]\n",
    "\n",
    "input = tf.reshape(input_array,[1,28,28,1])\n",
    "time_before = int(round(time.time_ns() / 1000))\n",
    "predictions = model.predict(input)\n",
    "time_after = int(round(time.time_ns() / 1000))\n",
    "print(predictions)\n",
    "print(\"process time in microseconds: \" + str(time_after - time_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
