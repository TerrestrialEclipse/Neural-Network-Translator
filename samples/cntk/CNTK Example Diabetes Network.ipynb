{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network with Diabetes data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"../build neural networks/diabetes.csv\", delimiter=\",\", skiprows=1 )\n",
    "diabetes_X = dataset[:,0:8]\n",
    "diabetes_Y = dataset[:,8]\n",
    "diabetes_X = scale(diabetes_X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 8\n",
    "num_output_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random data sample\n",
    "def generate_random_data_sample(sample_size, feature_dim, num_classes):    \n",
    "    idx = np.random.choice(diabetes_X.shape[0], size=(sample_size, 1), replace=False)\n",
    "    X = diabetes_X[idx].astype(np.float32)\n",
    "    Y = diabetes_Y[idx]\n",
    "\n",
    "    # converting class 0 into the vector \"1 0 0\",\n",
    "    # class 1 into vector \"0 1 0\", ...\n",
    "    class_ind = [Y==class_number for class_number in range(num_classes)]\n",
    "    Y = np.asarray(np.hstack(class_ind), dtype=np.float32)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysamplesize = 64\n",
    "features, labels = generate_random_data_sample(mysamplesize, input_dim, num_output_classes)\n",
    "\n",
    "num_hidden_layers = 1\n",
    "hidden_layers_dim = 8\n",
    "\n",
    "input = C.input_variable(input_dim)\n",
    "label = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.layers.glorot_uniform(), activation=C.sigmoid):\n",
    "        h = features\n",
    "        for _ in range(num_hidden_layers):\n",
    "            h = C.layers.Dense(hidden_layers_dim, activation=C.sigmoid)(h)\n",
    "        last_layer = C.layers.Dense(num_output_classes, activation = None)\n",
    "\n",
    "        return last_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose:\n",
    "            print (\"Minibatch: {}, Train Loss: {}, Train Error: {}\".format(mb, training_loss, eval_error))\n",
    "\n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = C.cross_entropy_with_softmax(model, label)\n",
    "eval_error = C.classification_error(model, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "learner = C.sgd(model.parameters, lr_schedule)\n",
    "trainer = C.Trainer(model, (loss, eval_error), [learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 10\n",
    "num_minibatches_to_train = 300\n",
    "\n",
    "training_progress_output_freq = 20\n",
    "plotdata = {\"batchsize\":[], \"loss\":[], \"error\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, int(num_minibatches_to_train)):    \n",
    "    features, labels = generate_random_data_sample(minibatch_size, input_dim, num_output_classes)\n",
    "\n",
    "    # Specify the input variables mapping in the model to actual minibatch data for training\n",
    "    trainer.train_minibatch({input : features, label : labels})\n",
    "    batchsize, loss, error = print_training_progress(trainer, i,\n",
    "                                                     training_progress_output_freq, verbose=0)\n",
    "\n",
    "    if not (loss == \"NA\" or error ==\"NA\"):\n",
    "        plotdata[\"batchsize\"].append(batchsize)\n",
    "        plotdata[\"loss\"].append(loss)\n",
    "        plotdata[\"error\"].append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new data\n",
    "test_minibatch_size = 10\n",
    "#features, labels = generate_random_data_sample(test_minibatch_size, input_dim, num_output_classes)\n",
    "features, labels = generate_random_data_sample(test_minibatch_size, input_dim, num_output_classes)\n",
    "trainer.test_minibatch({input : features, label : labels})\n",
    "\n",
    "out = C.softmax(model)\n",
    "\n",
    "predicted_label_probs = out.eval({input : features})\n",
    "\n",
    "print(\"Label    :\", [np.argmax(label) for label in labels])\n",
    "print(\"Predicted:\", [np.argmax(row) for row in predicted_label_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_probs = model.eval(test_data)\n",
    "print(\"Predicted:\", [np.argmax(row) for row in predicted_label_probs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cntk_diabetes.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cntk.ops.functions import load_model\n",
    "\n",
    "z = load_model(\"cntk_diabetes.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = z.parameters\n",
    "for parameter in parameters:\n",
    "    print(parameter.name, parameter.shape, \"\\n\", parameter.value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read structure of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = C.logging.graph.depth_first_search(\n",
    "            model, (lambda x : type(x) == C.Function and x.is_block) , depth = 0)\n",
    "for layer in layers:\n",
    "    print(layer.op_name) #Typ des Layers z.B. Dense\n",
    "    print(layer.is_composite)\n",
    "    print(layer.arguments) \n",
    "    print(layer.constants)\n",
    "    print(layer.parameters)\n",
    "    print(layer.attributes)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
